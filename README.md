# ðŸš€ LLM Workshop: Build a Large Language Model From Scratch

**Duration**: 2 Days (4 Sessions Ã— 3 hours = 12 hours total)  
**Based on**: [rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) by Sebastian Raschka

---

## ðŸ“š Session Notebooks

| Session | Day | Time | Notebook | Topics |
|---------|-----|------|----------|--------|
| 1 | Day 1 | 9:30-12:30 | `Session1_Understanding_LLMs_Text_Data.ipynb` | LLM intro, tokenization, embeddings, DataLoader |
| 2 | Day 1 | 1:30-4:30 | `Session2_Attention_Mechanisms.ipynb` | Self-attention, scaled dot-product, multi-head attention |
| 3 | Day 2 | 9:30-12:30 | `Session3_GPT_Model.ipynb` | LayerNorm, GELU, FFN, TransformerBlock, GPT model |
| 4 | Day 2 | 1:30-4:30 | `Session4_Training_Finetuning.ipynb` | Pretraining, loading weights, finetuning, classification |

---

## ðŸ§  New Beginner Complete Pack (Age 15+)

- **Master beginner notebook**: `LLM_From_Scratch_Teen_Friendly_Master_Notebook.ipynb`
  - Full path from basic math to building/training/generating with a tiny GPT
  - Includes attention heatmaps, causal mask visualizations, and interactive generation controls
- **Student practice notebook**: `LLM_From_Scratch_Teen_Friendly_Student_Workbook.ipynb`
  - Exercise-first workbook with guided TODOs, plots, and interactive parameter experiments
- **PPT deck content**: `LLM_From_Scratch_Teen_Friendly_PPT_Content.md`
  - 21-slide complete structure for PowerPoint / Google Slides
- **PPT speaker notes**: `LLM_From_Scratch_Teen_Friendly_PPT_Speaker_Notes.md`
  - Delivery flow, timing, discussion prompts, and common Q&A support

---

## ðŸ”§ Setup Instructions

### Prerequisites
```bash
pip install torch tiktoken matplotlib numpy requests transformers
```

---

## ðŸ“– Notebook Features

Each notebook includes:
- ðŸ“¢ **Instructor scripts** - What to say during each section
- ðŸ’¡ **Key points** - Important concepts to emphasize
- ðŸ”§ **Hands-on code** - Complete working examples
- ðŸŽ¯ **Exercises** - Practice activities for students

---

## ðŸ“… Detailed Schedule

### Day 1
| Time | Session 1 Topic |
|------|-----------------|
| 9:30-10:15 | Introduction to LLMs (theory) |
| 10:15-10:30 | Break |
| 10:30-11:15 | Tokenization (hands-on) |
| 11:15-12:00 | Embeddings & DataLoader |
| 12:00-12:30 | Exercises & Q&A |

| Time | Session 2 Topic |
|------|-----------------|
| 1:30-2:00 | Attention intuition (theory) |
| 2:00-3:00 | Self-attention from scratch |
| 3:00-3:15 | Break |
| 3:15-4:15 | Multi-head attention |
| 4:15-4:30 | Exercises & recap |

### Day 2
| Time | Session 3 Topic |
|------|-----------------|
| 9:30-9:45 | Day 1 recap |
| 9:45-10:30 | GPT architecture overview |
| 10:30-10:45 | Break |
| 10:45-11:45 | Building GPT components |
| 11:45-12:30 | Complete model & generation |

| Time | Session 4 Topic |
|------|-----------------|
| 1:30-2:15 | Pretraining fundamentals |
| 2:15-2:45 | Loading pretrained weights |
| 2:45-3:00 | Break |
| 3:00-4:00 | Finetuning for classification |
| 4:00-4:30 | Workshop wrap-up |

---

## ðŸŽ“ Resources

- **Book**: [Build a Large Language Model From Scratch](https://www.manning.com/books/build-a-large-language-model-from-scratch)
- **GitHub**: [rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)
- **Video Course**: [Master and Build Large Language Models](https://www.manning.com/livevideo/master-and-build-large-language-models)

---

Good luck with your workshop! ðŸŽ‰
