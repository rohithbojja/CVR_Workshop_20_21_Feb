{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ“ Session 3: Implementing a GPT Model from Scratch\n",
                "\n",
                "**Workshop: Build a Large Language Model From Scratch**  \n",
                "**Duration**: 3 hours (9:30 AM - 12:30 PM)  \n",
                "**Day 2**\n",
                "\n",
                "**Instructor Notes**: ðŸ“¢ indicates what to say, ðŸ’¡ indicates key points to emphasize\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‹ Session Overview\n",
                "\n",
                "| Time | Topic | Type |\n",
                "|------|-------|------|\n",
                "| 9:30 - 9:45 | Day 1 Recap | Review |\n",
                "| 9:45 - 10:30 | GPT Architecture Overview | Theory + Code |\n",
                "| 10:30 - 10:45 | Break | - |\n",
                "| 10:45 - 11:45 | Building GPT Components | Hands-on |\n",
                "| 11:45 - 12:30 | Complete GPT Model + Generation | Hands-on |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 1: Day 1 Recap (15 min)\n",
                "---\n",
                "\n",
                "## ðŸ“¢ Instructor Script\n",
                "\n",
                "> \"Good morning and welcome to Day 2! Yesterday we learned:\n",
                "> 1. How to convert text to tokens (tokenization)\n",
                "> 2. How embeddings represent tokens as vectors\n",
                "> 3. How attention lets tokens 'look at' each other\n",
                "> \n",
                "> Today, we put it ALL together to build a complete GPT model!\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.7.1+cpu\n",
                        "Device: cpu\n",
                        "\n",
                        "âœ… Ready for Day 2!\n"
                    ]
                }
            ],
            "source": [
                "# Quick Setup\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import tiktoken\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
                "print(\"\\nâœ… Ready for Day 2!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2: GPT Architecture Overview (45 min)\n",
                "---\n",
                "\n",
                "## ðŸ“¢ Instructor Script\n",
                "> \"Let me show you the big picture of GPT. It's simpler than you might think!\"\n",
                "\n",
                "## ðŸ—ï¸ GPT Architecture\n",
                "\n",
                "```\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚           Token Embeddings              â”‚  â† Position in vocabulary\n",
                "â”‚         + Position Embeddings           â”‚  â† Position in sequence\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "                    â†“\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
                "â”‚     â”‚   Layer Normalization       â”‚     â”‚\n",
                "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
                "â”‚                   â†“                     â”‚\n",
                "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
                "â”‚     â”‚   Multi-Head Attention      â”‚     â”‚  â† From Session 2!\n",
                "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
                "â”‚                   â†“ (+residual)         â”‚\n",
                "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
                "â”‚     â”‚   Layer Normalization       â”‚     â”‚\n",
                "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
                "â”‚                   â†“                     â”‚\n",
                "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
                "â”‚     â”‚   Feed-Forward Network      â”‚     â”‚  â† Simple MLP\n",
                "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
                "â”‚                   â†“ (+residual)         â”‚\n",
                "â”‚         TRANSFORMER BLOCK Ã— N           â”‚  â† Repeat N times!\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "                    â†“\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚       Final Layer Normalization         â”‚\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "                    â†“\n",
                "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "â”‚     Linear Layer (to vocab size)        â”‚  â† Predict next token!\n",
                "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š GPT-2 Model Configurations\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"GPT-2 comes in 4 sizes. We'll build the smallest (124M) which is still impressive!\"\n",
                "\n",
                "| Model | Parameters | Layers | Heads | Embedding Dim |\n",
                "|-------|-----------|--------|-------|---------------|\n",
                "| GPT-2 Small | 124M | 12 | 12 | 768 |\n",
                "| GPT-2 Medium | 355M | 24 | 16 | 1024 |\n",
                "| GPT-2 Large | 774M | 36 | 20 | 1280 |\n",
                "| GPT-2 XL | 1.5B | 48 | 25 | 1600 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GPT-2 Small Configuration:\n",
                        "  vocab_size: 50257\n",
                        "  context_length: 1024\n",
                        "  emb_dim: 768\n",
                        "  n_heads: 12\n",
                        "  n_layers: 12\n",
                        "  drop_rate: 0.1\n",
                        "  qkv_bias: False\n"
                    ]
                }
            ],
            "source": [
                "# GPT-2 Small Configuration\n",
                "GPT_CONFIG_124M = {\n",
                "    \"vocab_size\": 50257,      # GPT-2 vocabulary size\n",
                "    \"context_length\": 1024,   # Maximum sequence length\n",
                "    \"emb_dim\": 768,           # Embedding dimension\n",
                "    \"n_heads\": 12,            # Number of attention heads\n",
                "    \"n_layers\": 12,           # Number of transformer blocks\n",
                "    \"drop_rate\": 0.1,         # Dropout rate\n",
                "    \"qkv_bias\": False         # Use bias in Q, K, V projections?\n",
                "}\n",
                "\n",
                "print(\"GPT-2 Small Configuration:\")\n",
                "for key, value in GPT_CONFIG_124M.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## â˜• BREAK (10:30 - 10:45)\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 3: Building GPT Components (60 min)\n",
                "---\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Now let's build each component from the bottom up. We'll start with Layer Normalization, then Feed-Forward, then the Transformer Block.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ Layer Normalization\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Layer Normalization stabilizes training by normalizing the activations. Unlike Batch Norm, it normalizes across features, not the batch.\"\n",
                "\n",
                "ðŸ’¡ **Formula:**\n",
                "$$\\text{LayerNorm}(x) = \\gamma \\cdot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LayerNorm(nn.Module):\n",
                "    \"\"\"Layer Normalization with learnable scale and shift.\"\"\"\n",
                "    \n",
                "    def __init__(self, emb_dim, eps=1e-5):\n",
                "        super().__init__()\n",
                "        self.eps = eps\n",
                "        self.scale = nn.Parameter(torch.ones(emb_dim))   # Î³ (gamma)\n",
                "        self.shift = nn.Parameter(torch.zeros(emb_dim))  # Î² (beta)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        mean = x.mean(dim=-1, keepdim=True)\n",
                "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
                "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
                "        return self.scale * norm_x + self.shift"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Before LayerNorm - Mean: 5.1056, Std: 10.0506\n",
                        "After LayerNorm  - Mean: -0.0000, Std: 1.0001\n"
                    ]
                }
            ],
            "source": [
                "# Test Layer Normalization\n",
                "torch.manual_seed(42)\n",
                "layer_norm = LayerNorm(768)\n",
                "\n",
                "# Create sample input with high variance\n",
                "sample = torch.randn(2, 4, 768) * 10 + 5  # mean ~5, std ~10\n",
                "normalized = layer_norm(sample)\n",
                "\n",
                "print(f\"Before LayerNorm - Mean: {sample.mean():.4f}, Std: {sample.std():.4f}\")\n",
                "print(f\"After LayerNorm  - Mean: {normalized.mean():.4f}, Std: {normalized.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ GELU Activation Function\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"GPT uses GELU instead of ReLU. GELU is smoother and works better for transformers.\"\n",
                "\n",
                "ðŸ’¡ **GELU vs ReLU:**\n",
                "- ReLU: max(0, x) - sharp cutoff at 0\n",
                "- GELU: x Â· Î¦(x) - smooth, probabilistic cutoff"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GELU(nn.Module):\n",
                "    \"\"\"Gaussian Error Linear Unit activation.\"\"\"\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return 0.5 * x * (1 + torch.tanh(\n",
                "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
                "            (x + 0.044715 * torch.pow(x, 3))\n",
                "        ))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x400 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Visualize GELU vs ReLU\n",
                "x = torch.linspace(-3, 3, 100)\n",
                "gelu = GELU()\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(x, gelu(x), label='GELU', linewidth=2)\n",
                "plt.plot(x, F.relu(x), label='ReLU', linewidth=2)\n",
                "plt.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
                "plt.axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
                "plt.legend()\n",
                "plt.title('GELU vs ReLU Activation Functions')\n",
                "plt.xlabel('Input')\n",
                "plt.ylabel('Output')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ Feed-Forward Network (MLP)\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"After attention, we pass through a simple MLP. It expands the dimension by 4x, applies GELU, then projects back.\"\n",
                "\n",
                "```\n",
                "768 â†’ 3072 (Ã—4) â†’ GELU â†’ 3072 â†’ 768\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FeedForward(nn.Module):\n",
                "    \"\"\"Feed-Forward Network in Transformer block.\"\"\"\n",
                "    \n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        self.layers = nn.Sequential(\n",
                "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
                "            GELU(),\n",
                "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
                "            nn.Dropout(cfg[\"drop_rate\"])\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return self.layers(x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Input shape: torch.Size([2, 4, 768])\n",
                        "Output shape: torch.Size([2, 4, 768])\n",
                        "\n",
                        "Feed-Forward parameters: 4,722,432\n",
                        "  Linear 1: 768 Ã— 3072 + 3072 = 2,362,368\n",
                        "  Linear 2: 3072 Ã— 768 + 768 = 2,360,064\n"
                    ]
                }
            ],
            "source": [
                "# Test Feed-Forward\n",
                "ffn = FeedForward(GPT_CONFIG_124M)\n",
                "sample = torch.randn(2, 4, 768)\n",
                "output = ffn(sample)\n",
                "\n",
                "print(f\"Input shape: {sample.shape}\")\n",
                "print(f\"Output shape: {output.shape}\")\n",
                "\n",
                "# Count parameters\n",
                "ffn_params = sum(p.numel() for p in ffn.parameters())\n",
                "print(f\"\\nFeed-Forward parameters: {ffn_params:,}\")\n",
                "print(f\"  Linear 1: 768 Ã— 3072 + 3072 = {768 * 3072 + 3072:,}\")\n",
                "print(f\"  Linear 2: 3072 Ã— 768 + 768 = {3072 * 768 + 768:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ Multi-Head Attention (from Session 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MultiHeadAttention(nn.Module):\n",
                "    \"\"\"Multi-Head Causal Self-Attention.\"\"\"\n",
                "    \n",
                "    def __init__(self, d_in, d_out, context_length, num_heads, dropout=0.0, qkv_bias=False):\n",
                "        super().__init__()\n",
                "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
                "        \n",
                "        self.d_out = d_out\n",
                "        self.num_heads = num_heads\n",
                "        self.head_dim = d_out // num_heads\n",
                "        \n",
                "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
                "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
                "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
                "        self.out_proj = nn.Linear(d_out, d_out)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        \n",
                "        self.register_buffer(\n",
                "            'mask',\n",
                "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        batch_size, seq_len, d_in = x.shape\n",
                "        \n",
                "        Q = self.W_query(x)\n",
                "        K = self.W_key(x)\n",
                "        V = self.W_value(x)\n",
                "        \n",
                "        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        \n",
                "        attn_scores = Q @ K.transpose(-2, -1) / (self.head_dim ** 0.5)\n",
                "        attn_scores = attn_scores.masked_fill(\n",
                "            self.mask[:seq_len, :seq_len].bool(), float('-inf')\n",
                "        )\n",
                "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
                "        attn_weights = self.dropout(attn_weights)\n",
                "        \n",
                "        context = attn_weights @ V\n",
                "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_out)\n",
                "        \n",
                "        return self.out_proj(context)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ Transformer Block\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Now we combine attention, FFN, and layer norm into one Transformer Block. Notice the residual connections - they're crucial!\"\n",
                "\n",
                "```\n",
                "x â†’ LayerNorm â†’ MultiHeadAttn â†’ + â†’ LayerNorm â†’ FFN â†’ + â†’ output\n",
                "     â†‘                          â†‘              â†‘        â†‘\n",
                "     â””â”€â”€â”€â”€â”€â”€â”€â”€ (residual) â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€ (residual)â”€â”€â”˜\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TransformerBlock(nn.Module):\n",
                "    \"\"\"A single Transformer block (GPT-style).\"\"\"\n",
                "    \n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        self.att = MultiHeadAttention(\n",
                "            d_in=cfg[\"emb_dim\"],\n",
                "            d_out=cfg[\"emb_dim\"],\n",
                "            context_length=cfg[\"context_length\"],\n",
                "            num_heads=cfg[\"n_heads\"],\n",
                "            dropout=cfg[\"drop_rate\"],\n",
                "            qkv_bias=cfg[\"qkv_bias\"]\n",
                "        )\n",
                "        self.ff = FeedForward(cfg)\n",
                "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
                "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
                "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Attention block with residual\n",
                "        shortcut = x\n",
                "        x = self.norm1(x)\n",
                "        x = self.att(x)\n",
                "        x = self.drop_shortcut(x)\n",
                "        x = x + shortcut\n",
                "        \n",
                "        # FFN block with residual\n",
                "        shortcut = x\n",
                "        x = self.norm2(x)\n",
                "        x = self.ff(x)\n",
                "        x = self.drop_shortcut(x)\n",
                "        x = x + shortcut\n",
                "        \n",
                "        return x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Input shape: torch.Size([2, 4, 768])\n",
                        "Output shape: torch.Size([2, 4, 768])\n",
                        "\n",
                        "Transformer Block parameters: 7,085,568\n"
                    ]
                }
            ],
            "source": [
                "# Test Transformer Block\n",
                "torch.manual_seed(42)\n",
                "block = TransformerBlock(GPT_CONFIG_124M)\n",
                "\n",
                "sample = torch.randn(2, 4, 768)\n",
                "output = block(sample)\n",
                "\n",
                "print(f\"Input shape: {sample.shape}\")\n",
                "print(f\"Output shape: {output.shape}\")\n",
                "\n",
                "block_params = sum(p.numel() for p in block.parameters())\n",
                "print(f\"\\nTransformer Block parameters: {block_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 4: Complete GPT Model (45 min)\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ The Full GPT Model\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Now for the grand finale! We stack everything together into the complete GPT model.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GPTModel(nn.Module):\n",
                "    \"\"\"Complete GPT Model.\"\"\"\n",
                "    \n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Token and position embeddings\n",
                "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
                "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
                "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
                "        \n",
                "        # Transformer blocks\n",
                "        self.trf_blocks = nn.Sequential(\n",
                "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
                "        )\n",
                "        \n",
                "        # Final layer norm and output head\n",
                "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
                "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
                "    \n",
                "    def forward(self, in_idx):\n",
                "        batch_size, seq_len = in_idx.shape\n",
                "        \n",
                "        # Get embeddings\n",
                "        tok_embeds = self.tok_emb(in_idx)\n",
                "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
                "        x = tok_embeds + pos_embeds\n",
                "        x = self.drop_emb(x)\n",
                "        \n",
                "        # Pass through transformer blocks\n",
                "        x = self.trf_blocks(x)\n",
                "        \n",
                "        # Final norm and project to vocabulary\n",
                "        x = self.final_norm(x)\n",
                "        logits = self.out_head(x)\n",
                "        \n",
                "        return logits"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "ðŸŽ‰ Total GPT-2 Small Parameters: 163,009,536\n",
                        "   That's 163.0 million parameters!\n"
                    ]
                }
            ],
            "source": [
                "# Create GPT model!\n",
                "torch.manual_seed(42)\n",
                "model = GPTModel(GPT_CONFIG_124M)\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\nðŸŽ‰ Total GPT-2 Small Parameters: {total_params:,}\")\n",
                "print(f\"   That's {total_params / 1e6:.1f} million parameters!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Input text: 'Hello, world!'\n",
                        "Token IDs: [15496, 11, 995, 0]\n",
                        "Input tensor shape: torch.Size([1, 4])\n",
                        "\n",
                        "Output logits shape: torch.Size([1, 4, 50257])\n",
                        "This is: (batch_size=1, seq_len=4, vocab_size=50257)\n"
                    ]
                }
            ],
            "source": [
                "# Test forward pass\n",
                "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
                "text = \"Hello, world!\"\n",
                "token_ids = tokenizer.encode(text)\n",
                "input_tensor = torch.tensor(token_ids).unsqueeze(0)  # Add batch dimension\n",
                "\n",
                "print(f\"Input text: '{text}'\")\n",
                "print(f\"Token IDs: {token_ids}\")\n",
                "print(f\"Input tensor shape: {input_tensor.shape}\")\n",
                "\n",
                "# Forward pass\n",
                "with torch.no_grad():\n",
                "    logits = model(input_tensor)\n",
                "\n",
                "print(f\"\\nOutput logits shape: {logits.shape}\")\n",
                "print(f\"This is: (batch_size=1, seq_len={len(token_ids)}, vocab_size={GPT_CONFIG_124M['vocab_size']})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”® Text Generation!\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Now let's generate text! We'll predict one token at a time, add it to the input, and repeat. This is called **autoregressive generation**.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
                "    \"\"\"Generate text one token at a time.\"\"\"\n",
                "    for _ in range(max_new_tokens):\n",
                "        # Crop to context window\n",
                "        idx_cond = idx[:, -context_size:]\n",
                "        \n",
                "        # Get predictions\n",
                "        with torch.no_grad():\n",
                "            logits = model(idx_cond)\n",
                "        \n",
                "        # Focus on last token's prediction\n",
                "        logits = logits[:, -1, :]  # (batch, vocab_size)\n",
                "        \n",
                "        # Get token with highest probability\n",
                "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
                "        \n",
                "        # Append to sequence\n",
                "        idx = torch.cat((idx, idx_next), dim=1)\n",
                "    \n",
                "    return idx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting text: 'Hello, I am'\n",
                        "Starting tokens: [15496, 11, 314, 716]\n",
                        "\n",
                        "Generated text: 'Hello, I am authority rainbowriganBrave lobster Tian surprisinglyabul CertainGS formallyrait 239berry joking Visitors polic procession inter firing'\n",
                        "\n",
                        "ðŸ’¡ It's gibberish because the model has random weights!\n",
                        "   We'll fix this by loading pretrained weights in Session 4!\n"
                    ]
                }
            ],
            "source": [
                "# Generate text (with random weights - will be gibberish!)\n",
                "start_text = \"Hello, I am\"\n",
                "start_ids = tokenizer.encode(start_text)\n",
                "start_tensor = torch.tensor(start_ids).unsqueeze(0)\n",
                "\n",
                "print(f\"Starting text: '{start_text}'\")\n",
                "print(f\"Starting tokens: {start_ids}\\n\")\n",
                "\n",
                "# Generate 20 new tokens\n",
                "generated = generate_text_simple(\n",
                "    model, \n",
                "    start_tensor, \n",
                "    max_new_tokens=20,\n",
                "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
                ")\n",
                "\n",
                "generated_text = tokenizer.decode(generated[0].tolist())\n",
                "print(f\"Generated text: '{generated_text}'\")\n",
                "print(\"\\nðŸ’¡ It's gibberish because the model has random weights!\")\n",
                "print(\"   We'll fix this by loading pretrained weights in Session 4!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ² Adding Randomness: Temperature Sampling\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Using argmax always picks the most likely token - boring! We can add randomness with **temperature sampling**.\"\n",
                "\n",
                "ðŸ’¡ **Temperature:**\n",
                "- Low (0.1-0.5): More deterministic, focused\n",
                "- Medium (0.7-0.9): Balanced\n",
                "- High (1.0+): More random, creative"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_text(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=None):\n",
                "    \"\"\"Generate text with temperature and optional top-k sampling.\"\"\"\n",
                "    for _ in range(max_new_tokens):\n",
                "        idx_cond = idx[:, -context_size:]\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            logits = model(idx_cond)\n",
                "        \n",
                "        logits = logits[:, -1, :]\n",
                "        \n",
                "        # Apply temperature\n",
                "        if temperature > 0:\n",
                "            logits = logits / temperature\n",
                "            \n",
                "            # Optional: top-k filtering\n",
                "            if top_k is not None:\n",
                "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
                "                logits[logits < v[:, [-1]]] = float('-inf')\n",
                "            \n",
                "            probs = F.softmax(logits, dim=-1)\n",
                "            idx_next = torch.multinomial(probs, num_samples=1)\n",
                "        else:\n",
                "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
                "        \n",
                "        idx = torch.cat((idx, idx_next), dim=1)\n",
                "    \n",
                "    return idx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating with different temperatures:\n",
                        "\n",
                        "Temperature 0.5: Hello, I am entrepreneur Max Ord nutspictured Comet Tourism Hung disinformation redundancy Aerialravel bind skullsInst\n",
                        "Temperature 1.0: Hello, I am entrepreneur Max Ord nutspictured Comet Tourism Hung disinformation ran contrastinglearning 269aghpre\n",
                        "Temperature 1.5: Hello, I am entrepreneur Max Ord nutspictured Comet Tourism Hung disinformation ran contrastinglearning 269aghpre\n"
                    ]
                }
            ],
            "source": [
                "# Generate with different temperatures\n",
                "print(\"Generating with different temperatures:\\n\")\n",
                "\n",
                "for temp in [0.5, 1.0, 1.5]:\n",
                "    torch.manual_seed(42)  # For reproducibility\n",
                "    generated = generate_text(\n",
                "        model, start_tensor, \n",
                "        max_new_tokens=15,\n",
                "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
                "        temperature=temp,\n",
                "        top_k=50\n",
                "    )\n",
                "    text = tokenizer.decode(generated[0].tolist())\n",
                "    print(f\"Temperature {temp}: {text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ“ Session 3 Summary\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Incredible work! We just built a complete GPT model from scratch!\"\n",
                "\n",
                "### What We Built Today:\n",
                "\n",
                "1. **Layer Normalization** - Stabilizes training\n",
                "2. **GELU Activation** - Better than ReLU for transformers\n",
                "3. **Feed-Forward Network** - 768 â†’ 3072 â†’ 768\n",
                "4. **Transformer Block** - Attention + FFN + Residuals\n",
                "5. **Complete GPT Model** - 12 blocks, 124M parameters!\n",
                "6. **Text Generation** - Autoregressive + temperature sampling\n",
                "\n",
                "### Next Session:\n",
                "> \"This afternoon, we'll load pretrained weights and see real text generation. Then we'll learn about training and finetuning!\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸŽ¯ Quick Exercises\n",
                "\n",
                "**Exercise 1:** Calculate the total parameters in each component:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Parameter breakdown:\n",
                        "  Token embeddings: 38,597,376\n",
                        "  Position embeddings: 786,432\n",
                        "  Transformer blocks: 85,026,816\n",
                        "  Final LayerNorm: 1,536\n",
                        "  Output head: 38,597,376\n",
                        "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "  Total: 163,009,536\n"
                    ]
                }
            ],
            "source": [
                "# TODO: Print parameter count for each component\n",
                "print(\"Parameter breakdown:\")\n",
                "print(f\"  Token embeddings: {model.tok_emb.weight.numel():,}\")\n",
                "print(f\"  Position embeddings: {model.pos_emb.weight.numel():,}\")\n",
                "print(f\"  Transformer blocks: {sum(p.numel() for p in model.trf_blocks.parameters()):,}\")\n",
                "print(f\"  Final LayerNorm: {sum(p.numel() for p in model.final_norm.parameters()):,}\")\n",
                "print(f\"  Output head: {model.out_head.weight.numel():,}\")\n",
                "print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
                "print(f\"  Total: {sum(p.numel() for p in model.parameters()):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Exercise 2:** Try generating with the same prompt multiple times (different random seeds):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prompt: 'The future of AI is'\n",
                        "\n",
                        "Output 1: The future of AI isKNInternet lucplatform numbering overcrowdlegal HofCondition gaping\n",
                        "Output 2: The future of AI isutingariosuter cardiovascularulin164 turbulentourse Color509\n",
                        "Output 3: The future of AI is312mittingule Patosis vaccetsu selling Brendan cheap\n"
                    ]
                }
            ],
            "source": [
                "# TODO: Generate 3 different outputs from the same prompt\n",
                "prompt = \"The future of AI is\"\n",
                "prompt_ids = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
                "\n",
                "print(f\"Prompt: '{prompt}'\\n\")\n",
                "for i in range(3):\n",
                "    torch.manual_seed(i)\n",
                "    output = generate_text(\n",
                "        model, prompt_ids, max_new_tokens=10,\n",
                "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
                "        temperature=1.0, top_k=50\n",
                "    )\n",
                "    print(f\"Output {i+1}: {tokenizer.decode(output[0].tolist())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸ”— Resources\n",
                "\n",
                "- [LLMs from Scratch - Chapter 4](https://github.com/rasbt/LLMs-from-scratch/tree/main/ch04)\n",
                "- [GPT-2 Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
                "- [Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
