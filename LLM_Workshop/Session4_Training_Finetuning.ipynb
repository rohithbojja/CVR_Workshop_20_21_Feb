{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ“ Session 4: Pretraining & Finetuning LLMs\n",
                "\n",
                "**Workshop: Build a Large Language Model From Scratch**  \n",
                "**Duration**: 3 hours (1:30 PM - 4:30 PM)  \n",
                "**Day 2 - Final Session**\n",
                "\n",
                "**Instructor Notes**: ðŸ“¢ indicates what to say, ðŸ’¡ indicates key points to emphasize\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‹ Session Overview\n",
                "\n",
                "| Time | Topic | Type |\n",
                "|------|-------|------|\n",
                "| 1:30 - 2:15 | Pretraining Fundamentals | Theory + Demo |\n",
                "| 2:15 - 2:45 | Loading Pretrained Weights | Hands-on |\n",
                "| 2:45 - 3:00 | Break | - |\n",
                "| 3:00 - 4:00 | Finetuning for Classification | Hands-on |\n",
                "| 4:00 - 4:30 | Workshop Wrap-up & Next Steps | Discussion |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 1: Pretraining Fundamentals (45 min)\n",
                "---\n",
                "\n",
                "## ðŸ“¢ Instructor Script\n",
                "\n",
                "> \"Welcome to our final session! This morning we built a complete GPT model with random weights. Now we'll learn how to:\n",
                "> 1. **Pretrain** it (or load pretrained weights)\n",
                "> 2. **Finetune** it for specific tasks\n",
                "> \n",
                "> Let's make our model actually work!\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PyTorch: 2.8.0+cu129\n",
                        "Device: cuda\n"
                    ]
                }
            ],
            "source": [
                "# Setup\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import tiktoken\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import os\n",
                "import requests\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… All model classes loaded!\n"
                    ]
                }
            ],
            "source": [
                "# Copy all model classes from Session 3 (in practice, import from module)\n",
                "\n",
                "class LayerNorm(nn.Module):\n",
                "    def __init__(self, emb_dim, eps=1e-5):\n",
                "        super().__init__()\n",
                "        self.eps = eps\n",
                "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
                "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
                "    \n",
                "    def forward(self, x):\n",
                "        mean = x.mean(dim=-1, keepdim=True)\n",
                "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
                "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
                "        return self.scale * norm_x + self.shift\n",
                "\n",
                "class GELU(nn.Module):\n",
                "    def forward(self, x):\n",
                "        return 0.5 * x * (1 + torch.tanh(\n",
                "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
                "            (x + 0.044715 * torch.pow(x, 3))\n",
                "        ))\n",
                "\n",
                "class FeedForward(nn.Module):\n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        self.layers = nn.Sequential(\n",
                "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
                "            GELU(),\n",
                "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
                "            nn.Dropout(cfg[\"drop_rate\"])\n",
                "        )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return self.layers(x)\n",
                "\n",
                "class MultiHeadAttention(nn.Module):\n",
                "    def __init__(self, d_in, d_out, context_length, num_heads, dropout=0.0, qkv_bias=False):\n",
                "        super().__init__()\n",
                "        assert d_out % num_heads == 0\n",
                "        self.d_out = d_out\n",
                "        self.num_heads = num_heads\n",
                "        self.head_dim = d_out // num_heads\n",
                "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
                "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
                "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
                "        self.out_proj = nn.Linear(d_out, d_out)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
                "    \n",
                "    def forward(self, x):\n",
                "        batch_size, seq_len, d_in = x.shape\n",
                "        Q = self.W_query(x)\n",
                "        K = self.W_key(x)\n",
                "        V = self.W_value(x)\n",
                "        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
                "        attn_scores = Q @ K.transpose(-2, -1) / (self.head_dim ** 0.5)\n",
                "        attn_scores = attn_scores.masked_fill(self.mask[:seq_len, :seq_len].bool(), float('-inf'))\n",
                "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
                "        attn_weights = self.dropout(attn_weights)\n",
                "        context = attn_weights @ V\n",
                "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_out)\n",
                "        return self.out_proj(context)\n",
                "\n",
                "class TransformerBlock(nn.Module):\n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        self.att = MultiHeadAttention(\n",
                "            d_in=cfg[\"emb_dim\"], d_out=cfg[\"emb_dim\"],\n",
                "            context_length=cfg[\"context_length\"], num_heads=cfg[\"n_heads\"],\n",
                "            dropout=cfg[\"drop_rate\"], qkv_bias=cfg[\"qkv_bias\"]\n",
                "        )\n",
                "        self.ff = FeedForward(cfg)\n",
                "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
                "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
                "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        shortcut = x\n",
                "        x = self.norm1(x)\n",
                "        x = self.att(x)\n",
                "        x = self.drop_shortcut(x)\n",
                "        x = x + shortcut\n",
                "        shortcut = x\n",
                "        x = self.norm2(x)\n",
                "        x = self.ff(x)\n",
                "        x = self.drop_shortcut(x)\n",
                "        x = x + shortcut\n",
                "        return x\n",
                "\n",
                "class GPTModel(nn.Module):\n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
                "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
                "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
                "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
                "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
                "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
                "    \n",
                "    def forward(self, in_idx):\n",
                "        batch_size, seq_len = in_idx.shape\n",
                "        tok_embeds = self.tok_emb(in_idx)\n",
                "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
                "        x = tok_embeds + pos_embeds\n",
                "        x = self.drop_emb(x)\n",
                "        x = self.trf_blocks(x)\n",
                "        x = self.final_norm(x)\n",
                "        logits = self.out_head(x)\n",
                "        return logits\n",
                "\n",
                "GPT_CONFIG_124M = {\n",
                "    \"vocab_size\": 50257,\n",
                "    \"context_length\": 1024,\n",
                "    \"emb_dim\": 768,\n",
                "    \"n_heads\": 12,\n",
                "    \"n_layers\": 12,\n",
                "    \"drop_rate\": 0.1,\n",
                "    \"qkv_bias\": False\n",
                "}\n",
                "\n",
                "print(\"âœ… All model classes loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ What is Pretraining?\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Pretraining is teaching the model to predict the next word on MASSIVE amounts of text. GPT-2 was trained on 40GB of text from 8 million web pages!\"\n",
                "\n",
                "ðŸ’¡ **Key Points:**\n",
                "- **Objective**: Next-token prediction (causal language modeling)\n",
                "- **Data**: Billions of tokens from books, websites, code\n",
                "- **Compute**: Thousands of GPU hours (we won't pretrain from scratch!)\n",
                "- **Result**: General language understanding"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‰ The Training Loop: Loss Function\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"We use Cross-Entropy Loss - it measures how well the model's probability distribution matches the actual next token.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calc_loss_batch(input_batch, target_batch, model, device):\n",
                "    \"\"\"Calculate cross-entropy loss for a batch.\"\"\"\n",
                "    input_batch = input_batch.to(device)\n",
                "    target_batch = target_batch.to(device)\n",
                "    \n",
                "    logits = model(input_batch)\n",
                "    \n",
                "    # Reshape for cross-entropy\n",
                "    # logits: (batch, seq_len, vocab_size) -> (batch*seq_len, vocab_size)\n",
                "    # targets: (batch, seq_len) -> (batch*seq_len)\n",
                "    loss = F.cross_entropy(\n",
                "        logits.flatten(0, 1),\n",
                "        target_batch.flatten()\n",
                "    )\n",
                "    return loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loss with random weights: 10.9118\n",
                        "Perplexity: 54819.51\n",
                        "\n",
                        "ðŸ’¡ Random guess perplexity would be ~50,257 (vocab size)\n",
                        "   Good model perplexity is ~20-50\n"
                    ]
                }
            ],
            "source": [
                "# Demo: Calculate loss on random model\n",
                "torch.manual_seed(42)\n",
                "model = GPTModel(GPT_CONFIG_124M)\n",
                "model.to(device)\n",
                "\n",
                "# Create dummy batch\n",
                "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
                "text = \"Hello, this is a test of the language model.\"\n",
                "tokens = tokenizer.encode(text)\n",
                "\n",
                "# Input = all tokens except last, Target = all tokens except first\n",
                "input_batch = torch.tensor([tokens[:-1]])\n",
                "target_batch = torch.tensor([tokens[1:]])\n",
                "\n",
                "loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
                "print(f\"Loss with random weights: {loss.item():.4f}\")\n",
                "print(f\"Perplexity: {torch.exp(loss).item():.2f}\")\n",
                "print(f\"\\nðŸ’¡ Random guess perplexity would be ~50,257 (vocab size)\")\n",
                "print(f\"   Good model perplexity is ~20-50\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ‹ï¸ Simple Training Loop Demo\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Let me show you a mini training loop on a tiny dataset. This won't produce a good model, but shows the process!\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a tiny dataset for demo\n",
                "class TinyDataset(Dataset):\n",
                "    def __init__(self, text, tokenizer, max_length=64, stride=32):\n",
                "        self.input_ids = []\n",
                "        self.target_ids = []\n",
                "        token_ids = tokenizer.encode(text)\n",
                "        for i in range(0, len(token_ids) - max_length, stride):\n",
                "            input_chunk = token_ids[i:i + max_length]\n",
                "            target_chunk = token_ids[i + 1:i + max_length + 1]\n",
                "            self.input_ids.append(torch.tensor(input_chunk))\n",
                "            self.target_ids.append(torch.tensor(target_chunk))\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.input_ids)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.input_ids[idx], self.target_ids[idx]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset size: 159 samples\n",
                        "Batches per epoch: 40\n"
                    ]
                }
            ],
            "source": [
                "# Download sample text\n",
                "if not os.path.exists(\"the-verdict.txt\"):\n",
                "    url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
                "    response = requests.get(url)\n",
                "    with open(\"the-verdict.txt\", \"w\", encoding=\"utf-8\") as f:\n",
                "        f.write(response.text)\n",
                "\n",
                "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
                "    text = f.read()\n",
                "\n",
                "# Create dataset\n",
                "dataset = TinyDataset(text, tokenizer, max_length=64, stride=32)\n",
                "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
                "\n",
                "print(f\"Dataset size: {len(dataset)} samples\")\n",
                "print(f\"Batches per epoch: {len(dataloader)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mini training loop (just a few steps for demo)\n",
                "def train_model_simple(model, dataloader, num_epochs=2):\n",
                "    optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4)\n",
                "    model.train()\n",
                "    \n",
                "    losses = []\n",
                "    for epoch in range(num_epochs):\n",
                "        epoch_loss = 0\n",
                "        for batch_idx, (input_batch, target_batch) in enumerate(dataloader):\n",
                "            optimizer.zero_grad()\n",
                "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            epoch_loss += loss.item()\n",
                "            losses.append(loss.item())\n",
                "            \n",
                "            if batch_idx % 10 == 0:\n",
                "                print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
                "        \n",
                "        avg_loss = epoch_loss / len(dataloader)\n",
                "        print(f\"\\nâ†’ Epoch {epoch+1} average loss: {avg_loss:.4f}\\n\")\n",
                "    \n",
                "    return losses"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting mini training demo...\n",
                        "\n",
                        "Epoch 1, Batch 0, Loss: 10.9824\n",
                        "Epoch 1, Batch 10, Loss: 7.6256\n",
                        "Epoch 1, Batch 20, Loss: 6.5499\n",
                        "Epoch 1, Batch 30, Loss: 6.4095\n",
                        "\n",
                        "â†’ Epoch 1 average loss: 7.3989\n",
                        "\n",
                        "Epoch 2, Batch 0, Loss: 5.8934\n",
                        "Epoch 2, Batch 10, Loss: 6.1536\n",
                        "Epoch 2, Batch 20, Loss: 5.9242\n",
                        "Epoch 2, Batch 30, Loss: 5.5029\n",
                        "\n",
                        "â†’ Epoch 2 average loss: 5.8097\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x400 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Run mini training (this will take ~30 seconds)\n",
                "print(\"Starting mini training demo...\\n\")\n",
                "torch.manual_seed(42)\n",
                "mini_model = GPTModel(GPT_CONFIG_124M)\n",
                "mini_model.to(device)\n",
                "\n",
                "losses = train_model_simple(mini_model, dataloader, num_epochs=2)\n",
                "\n",
                "# Plot loss\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(losses)\n",
                "plt.xlabel('Training Steps')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Training Loss (Decreasing = Model is Learning!)')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2: Loading Pretrained Weights (30 min)\n",
                "---\n",
                "\n",
                "## ðŸ“¢ Instructor Script\n",
                "> \"Training from scratch takes too long. Instead, let's load OpenAI's pretrained GPT-2 weights into our model!\"\n",
                "\n",
                "> \"This is the magic moment - our model will actually generate coherent text!\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We'll use a simplified weight loading approach\n",
                "# In practice, you'd download from OpenAI or Hugging Face\n",
                "\n",
                "def load_gpt2_weights_from_hf(model, model_name=\"gpt2\"):\n",
                "    \"\"\"Load pretrained weights from Hugging Face.\"\"\"\n",
                "    try:\n",
                "        from transformers import GPT2LMHeadModel\n",
                "        \n",
                "        print(f\"Loading {model_name} from Hugging Face...\")\n",
                "        hf_model = GPT2LMHeadModel.from_pretrained(model_name)\n",
                "        hf_dict = hf_model.state_dict()\n",
                "        \n",
                "        # Map Hugging Face keys to our model keys\n",
                "        # This is a simplified version - real implementation needs careful mapping\n",
                "        with torch.no_grad():\n",
                "            # Token embeddings\n",
                "            model.tok_emb.weight.copy_(hf_dict['transformer.wte.weight'])\n",
                "            # Position embeddings\n",
                "            model.pos_emb.weight.copy_(hf_dict['transformer.wpe.weight'])\n",
                "            \n",
                "            # Transformer blocks\n",
                "            for i in range(len(model.trf_blocks)):\n",
                "                # Attention weights\n",
                "                qkv = hf_dict[f'transformer.h.{i}.attn.c_attn.weight']\n",
                "                q, k, v = qkv.split(768, dim=1)\n",
                "                model.trf_blocks[i].att.W_query.weight.copy_(q.T)\n",
                "                model.trf_blocks[i].att.W_key.weight.copy_(k.T)\n",
                "                model.trf_blocks[i].att.W_value.weight.copy_(v.T)\n",
                "                model.trf_blocks[i].att.out_proj.weight.copy_(\n",
                "                    hf_dict[f'transformer.h.{i}.attn.c_proj.weight'].T)\n",
                "                model.trf_blocks[i].att.out_proj.bias.copy_(\n",
                "                    hf_dict[f'transformer.h.{i}.attn.c_proj.bias'])\n",
                "                # Attention biases\n",
                "                qkv_b = hf_dict[f'transformer.h.{i}.attn.c_attn.bias']\n",
                "                q_b, k_b, v_b = qkv_b.split(768)\n",
                "                model.trf_blocks[i].att.W_query.bias.copy_(q_b)\n",
                "                model.trf_blocks[i].att.W_key.bias.copy_(k_b)\n",
                "                model.trf_blocks[i].att.W_value.bias.copy_(v_b)\n",
                "                # FFN weights\n",
                "                model.trf_blocks[i].ff.layers[0].weight.copy_(\n",
                "                    hf_dict[f'transformer.h.{i}.mlp.c_fc.weight'].T)\n",
                "                model.trf_blocks[i].ff.layers[0].bias.copy_(\n",
                "                    hf_dict[f'transformer.h.{i}.mlp.c_fc.bias'])\n",
                "                model.trf_blocks[i].ff.layers[2].weight.copy_(\n",
                "                    hf_dict[f'transformer.h.{i}.mlp.c_proj.weight'].T)\n",
                "                model.trf_blocks[i].ff.layers[2].bias.copy_(\n",
                "                    hf_dict[f'transformer.h.{i}.mlp.c_proj.bias'])\n",
                "                \n",
                "                # LayerNorm\n",
                "                model.trf_blocks[i].norm1.scale.copy_(hf_dict[f'transformer.h.{i}.ln_1.weight'])\n",
                "                model.trf_blocks[i].norm1.shift.copy_(hf_dict[f'transformer.h.{i}.ln_1.bias'])\n",
                "                model.trf_blocks[i].norm2.scale.copy_(hf_dict[f'transformer.h.{i}.ln_2.weight'])\n",
                "                model.trf_blocks[i].norm2.shift.copy_(hf_dict[f'transformer.h.{i}.ln_2.bias'])\n",
                "            \n",
                "            # Final LayerNorm\n",
                "            model.final_norm.scale.copy_(hf_dict['transformer.ln_f.weight'])\n",
                "            model.final_norm.shift.copy_(hf_dict['transformer.ln_f.bias'])\n",
                "            \n",
                "            # Output head (weight tied with embeddings)\n",
                "            model.out_head.weight.copy_(hf_dict['transformer.wte.weight'])\n",
                "        \n",
                "        print(\"âœ… Weights loaded successfully!\")\n",
                "        return True\n",
                "    except ImportError:\n",
                "        print(\"âŒ transformers library not installed. Run: pip install transformers\")\n",
                "        return False\n",
                "    except Exception as e:\n",
                "        print(f\"âŒ Error loading weights: {e}\")\n",
                "        return False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading gpt2 from Hugging Face...\n",
                        "âœ… Weights loaded successfully!\n",
                        "\n",
                        "ðŸŽ‰ Model ready for generation!\n"
                    ]
                }
            ],
            "source": [
                "# Create model and load pretrained weights\n",
                "GPT_CONFIG_124M[\"qkv_bias\"] = True  # HF GPT-2 uses bias\n",
                "\n",
                "model = GPTModel(GPT_CONFIG_124M)\n",
                "success = load_gpt2_weights_from_hf(model, \"gpt2\")\n",
                "\n",
                "if success:\n",
                "    model.to(device)\n",
                "    model.eval()\n",
                "    print(f\"\\nðŸŽ‰ Model ready for generation!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”® Generate Real Text!\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Now for the magic moment! Let's generate some real text!\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_text(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=50):\n",
                "    \"\"\"Generate text with temperature and top-k sampling.\"\"\"\n",
                "    model.eval()\n",
                "    for _ in range(max_new_tokens):\n",
                "        idx_cond = idx[:, -context_size:]\n",
                "        with torch.no_grad():\n",
                "            logits = model(idx_cond)\n",
                "        logits = logits[:, -1, :]\n",
                "        \n",
                "        if temperature > 0:\n",
                "            logits = logits / temperature\n",
                "            if top_k is not None:\n",
                "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
                "                logits[logits < v[:, [-1]]] = float('-inf')\n",
                "            probs = F.softmax(logits, dim=-1)\n",
                "            idx_next = torch.multinomial(probs, num_samples=1)\n",
                "        else:\n",
                "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
                "        \n",
                "        idx = torch.cat((idx, idx_next), dim=1)\n",
                "    return idx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generated text with pretrained GPT-2:\n",
                        "\n",
                        "============================================================\n",
                        "\n",
                        "ðŸ“ The future of artificial intelligence is unknown.\"\n",
                        "\n",
                        "\"It's really difficult to say,\" said CTO of Microsoft's AI division, Mark Shuttleworth. A lot of the excitement for AI comes from the fact that it's possible to build machines from scratch.\n",
                        "\n",
                        "In the\n",
                        "------------------------------------------------------------\n",
                        "\n",
                        "ðŸ“ Once upon a time, in a land far away, there was no civilization, but the same things had happened. When I was young, I had never seen civilization before. When I was old, I knew there was no civilization, but I had never seen civilization before. When I was old, I\n",
                        "------------------------------------------------------------\n",
                        "\n",
                        "ðŸ“ The secret to success in life is overcoming the fear that things will get really difficult.\n",
                        "\n",
                        "The good news is that if you don't want to make the long journey, you can always take what is most important and offer it as a gift.\n",
                        "\n",
                        "4) You can be\n",
                        "------------------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Generate text!\n",
                "if success:\n",
                "    prompts = [\n",
                "        \"The future of artificial intelligence is\",\n",
                "        \"Once upon a time, in a land far away,\",\n",
                "        \"The secret to success in life is\",\n",
                "    ]\n",
                "    \n",
                "    print(\"Generated text with pretrained GPT-2:\\n\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    for prompt in prompts:\n",
                "        torch.manual_seed(42)\n",
                "        input_ids = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device)\n",
                "        \n",
                "        output = generate_text(\n",
                "            model, input_ids,\n",
                "            max_new_tokens=50,\n",
                "            context_size=GPT_CONFIG_124M[\"context_length\"],\n",
                "            temperature=0.8,\n",
                "            top_k=40\n",
                "        )\n",
                "        \n",
                "        generated = tokenizer.decode(output[0].tolist())\n",
                "        print(f\"\\nðŸ“ {generated}\")\n",
                "        print(\"-\" * 60)\n",
                "else:\n",
                "    print(\"âš ï¸ Pretrained weights not loaded. Install transformers: pip install transformers\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ðŸ“¢ **Say this:**\n",
                "> \"Look at that! Our model from scratch, with pretrained weights, is generating coherent English! This is what billions of parameters trained on internet text can do!\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## â˜• BREAK (2:45 - 3:00)\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 3: Finetuning for Classification (60 min)\n",
                "---\n",
                "\n",
                "## ðŸ“¢ Instructor Script\n",
                "> \"Pretrained models are great at general text, but what if we want them to do specific tasks? That's where **finetuning** comes in!\"\n",
                "\n",
                "> \"We'll finetune GPT-2 to classify movie reviews as positive or negative.\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Finetuning vs Pretraining\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "\n",
                "| Aspect | Pretraining | Finetuning |\n",
                "|--------|-------------|------------|\n",
                "| Goal | General language understanding | Specific task |\n",
                "| Data | Billions of tokens | Thousands of examples |\n",
                "| Time | Weeks | Minutes to hours |\n",
                "| Learning rate | Higher | Much lower |\n",
                "\n",
                "ðŸ’¡ **Types of Finetuning:**\n",
                "1. **Classification**: Add classification head (what we'll do!)\n",
                "2. **Instruction tuning**: Follow instructions (like ChatGPT)\n",
                "3. **RLHF**: Align with human preferences"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”§ Modifying GPT for Classification\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"For classification, we replace the language modeling head with a classification head. We only look at the last token's representation.\"\n",
                "\n",
                "```\n",
                "text â†’ GPT â†’ [hidden states] â†’ last token â†’ Classification Head â†’ Class\n",
                "                                   â†‘\n",
                "                     Use last position as representation\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GPTClassifier(nn.Module):\n",
                "    \"\"\"GPT model modified for text classification.\"\"\"\n",
                "    \n",
                "    def __init__(self, base_model, num_classes):\n",
                "        super().__init__()\n",
                "        self.model = base_model\n",
                "        emb_dim = base_model.out_head.in_features\n",
                "        \n",
                "        # Replace output head with classifier\n",
                "        self.model.out_head = nn.Linear(emb_dim, num_classes)\n",
                "    \n",
                "    def forward(self, input_ids):\n",
                "        # Get all hidden states\n",
                "        x = self.model.tok_emb(input_ids)\n",
                "        x = x + self.model.pos_emb(torch.arange(input_ids.shape[1], device=input_ids.device))\n",
                "        x = self.model.drop_emb(x)\n",
                "        x = self.model.trf_blocks(x)\n",
                "        x = self.model.final_norm(x)\n",
                "        \n",
                "        # Use last token for classification\n",
                "        last_hidden = x[:, -1, :]\n",
                "        logits = self.model.out_head(last_hidden)\n",
                "        return logits"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Create a Simple Classification Dataset\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Let's create a simple spam detection dataset for demonstration.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total samples: 20\n",
                        "Spam: 10\n",
                        "Not spam: 10\n"
                    ]
                }
            ],
            "source": [
                "# Simple spam dataset\n",
                "spam_data = [\n",
                "    (\"Congratulations! You've won a free iPhone!\", 1),\n",
                "    (\"Click here to claim your prize money now!\", 1),\n",
                "    (\"URGENT: Your account has been compromised!\", 1),\n",
                "    (\"You have been selected for a cash prize!\", 1),\n",
                "    (\"Free money! No strings attached!\", 1),\n",
                "    (\"Act now! Limited time offer!\", 1),\n",
                "    (\"Winner! You've been chosen!\", 1),\n",
                "    (\"Claim your free gift card today!\", 1),\n",
                "    (\"Hey, can we meet for lunch tomorrow?\", 0),\n",
                "    (\"The meeting has been rescheduled to 3pm.\", 0),\n",
                "    (\"Please review the attached document.\", 0),\n",
                "    (\"Thanks for your help with the project.\", 0),\n",
                "    (\"I'll send you the report by end of day.\", 0),\n",
                "    (\"Looking forward to our call next week.\", 0),\n",
                "    (\"Great work on the presentation!\", 0),\n",
                "    (\"Can you send me the updated file?\", 0),\n",
                "]\n",
                "\n",
                "# More data for training\n",
                "additional_spam = [\n",
                "    (\"EARN $$$ FROM HOME NOW!!!\", 1),\n",
                "    (\"Your loan has been approved!\", 1),\n",
                "    (\"Meeting notes from yesterday's call.\", 0),\n",
                "    (\"Project deadline extended to Friday.\", 0),\n",
                "]\n",
                "\n",
                "all_data = spam_data + additional_spam\n",
                "print(f\"Total samples: {len(all_data)}\")\n",
                "print(f\"Spam: {sum(1 for _, label in all_data if label == 1)}\")\n",
                "print(f\"Not spam: {sum(1 for _, label in all_data if label == 0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpamDataset(Dataset):\n",
                "    def __init__(self, data, tokenizer, max_length=64):\n",
                "        self.texts = []\n",
                "        self.labels = []\n",
                "        \n",
                "        for text, label in data:\n",
                "            tokens = tokenizer.encode(text)\n",
                "            # Pad or truncate to max_length\n",
                "            if len(tokens) > max_length:\n",
                "                tokens = tokens[:max_length]\n",
                "            else:\n",
                "                tokens = [tokenizer.encode(\" \")[0]] * (max_length - len(tokens)) + tokens\n",
                "            \n",
                "            self.texts.append(torch.tensor(tokens))\n",
                "            self.labels.append(label)\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.texts)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.texts[idx], self.labels[idx]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train samples: 14\n",
                        "Test samples: 6\n"
                    ]
                }
            ],
            "source": [
                "# Split data\n",
                "import random\n",
                "random.seed(42)\n",
                "random.shuffle(all_data)\n",
                "\n",
                "train_data = all_data[:14]\n",
                "test_data = all_data[14:]\n",
                "\n",
                "train_dataset = SpamDataset(train_data, tokenizer)\n",
                "test_dataset = SpamDataset(test_data, tokenizer)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=4)\n",
                "\n",
                "print(f\"Train samples: {len(train_dataset)}\")\n",
                "print(f\"Test samples: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ‹ï¸ Finetuning the Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_classifier(model, train_loader, test_loader, num_epochs=5, lr=1e-5):\n",
                "    \"\"\"Train classification model.\"\"\"\n",
                "    # Only optimize trainable parameters\n",
                "    optimizer = torch.optim.AdamW(\n",
                "        [p for p in model.parameters() if p.requires_grad], lr=lr\n",
                "    )\n",
                "    \n",
                "    train_losses = []\n",
                "    train_accs = []\n",
                "    \n",
                "    for epoch in range(num_epochs):\n",
                "        model.train()\n",
                "        total_loss = 0\n",
                "        correct = 0\n",
                "        total = 0\n",
                "        \n",
                "        for batch_texts, batch_labels in train_loader:\n",
                "            batch_texts = batch_texts.to(device)\n",
                "            batch_labels = batch_labels.to(device)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            logits = model(batch_texts)\n",
                "            loss = F.cross_entropy(logits, batch_labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            preds = torch.argmax(logits, dim=1)\n",
                "            correct += (preds == batch_labels).sum().item()\n",
                "            total += len(batch_labels)\n",
                "        \n",
                "        avg_loss = total_loss / len(train_loader)\n",
                "        accuracy = correct / total\n",
                "        train_losses.append(avg_loss)\n",
                "        train_accs.append(accuracy)\n",
                "        \n",
                "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2%}\")\n",
                "    \n",
                "    return train_losses, train_accs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading gpt2 from Hugging Face...\n",
                        "âœ… Weights loaded successfully!\n",
                        "\n",
                        "Trainable parameters: 7,090,946 / 124,441,346 (5.7%)\n"
                    ]
                }
            ],
            "source": [
                "# Create classifier from base model\n",
                "if success:\n",
                "    # Reload base model with fresh pretrained weights\n",
                "    base_model = GPTModel(GPT_CONFIG_124M)\n",
                "    load_gpt2_weights_from_hf(base_model, \"gpt2\")\n",
                "    \n",
                "    # Create classifier\n",
                "    classifier = GPTClassifier(base_model, num_classes=2)\n",
                "    classifier.to(device)\n",
                "    \n",
                "    # Freeze most layers (only train last layers + classifier head)\n",
                "    for param in classifier.model.parameters():\n",
                "        param.requires_grad = False\n",
                "    \n",
                "    # Unfreeze last transformer block and classifier head\n",
                "    for param in classifier.model.trf_blocks[-1].parameters():\n",
                "        param.requires_grad = True\n",
                "    for param in classifier.model.out_head.parameters():\n",
                "        param.requires_grad = True\n",
                "    for param in classifier.model.final_norm.parameters():\n",
                "        param.requires_grad = True\n",
                "    \n",
                "    \n",
                "    # Keep frozen layers in eval mode to disable dropout\n",
                "    classifier.eval()  # Set everything to eval\n",
                "    # Then selectively set trainable parts to train mode\n",
                "    classifier.model.trf_blocks[-1].train()\n",
                "    classifier.model.out_head.train()\n",
                "    classifier.model.final_norm.train()\n",
                "    trainable = sum(p.numel() for p in classifier.parameters() if p.requires_grad)\n",
                "    total = sum(p.numel() for p in classifier.parameters())\n",
                "    print(f\"\\nTrainable parameters: {trainable:,} / {total:,} ({trainable/total:.1%})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training spam classifier...\n",
                        "\n",
                        "Epoch 1/20 - Loss: 1.7144, Accuracy: 28.57%\n",
                        "Epoch 2/20 - Loss: 1.1536, Accuracy: 64.29%\n",
                        "Epoch 3/20 - Loss: 0.7607, Accuracy: 64.29%\n",
                        "Epoch 4/20 - Loss: 0.3373, Accuracy: 71.43%\n",
                        "Epoch 5/20 - Loss: 0.3367, Accuracy: 100.00%\n",
                        "Epoch 6/20 - Loss: 0.3268, Accuracy: 92.86%\n",
                        "Epoch 7/20 - Loss: 0.2033, Accuracy: 100.00%\n",
                        "Epoch 8/20 - Loss: 0.1047, Accuracy: 100.00%\n",
                        "Epoch 9/20 - Loss: 0.0514, Accuracy: 100.00%\n",
                        "Epoch 10/20 - Loss: 0.0286, Accuracy: 100.00%\n",
                        "Epoch 11/20 - Loss: 0.0174, Accuracy: 100.00%\n",
                        "Epoch 12/20 - Loss: 0.0126, Accuracy: 100.00%\n",
                        "Epoch 13/20 - Loss: 0.0049, Accuracy: 100.00%\n",
                        "Epoch 14/20 - Loss: 0.0024, Accuracy: 100.00%\n",
                        "Epoch 15/20 - Loss: 0.0036, Accuracy: 100.00%\n",
                        "Epoch 16/20 - Loss: 0.0011, Accuracy: 100.00%\n",
                        "Epoch 17/20 - Loss: 0.0011, Accuracy: 100.00%\n",
                        "Epoch 18/20 - Loss: 0.0029, Accuracy: 100.00%\n",
                        "Epoch 19/20 - Loss: 0.0029, Accuracy: 100.00%\n",
                        "Epoch 20/20 - Loss: 0.0013, Accuracy: 100.00%\n"
                    ]
                }
            ],
            "source": [
                "# Train classifier\n",
                "if success:\n",
                "    print(\"\\nTraining spam classifier...\\n\")\n",
                "    losses, accs = train_classifier(classifier, train_loader, test_loader, num_epochs=20, lr=5e-4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Test Set Predictions:\n",
                        "============================================================\n",
                        "âœ… True: SPAM | Pred: SPAM | 'URGENT: Your account has been compromise...'\n",
                        "âœ… True: SPAM | Pred: SPAM | 'EARN $$$ FROM HOME NOW!!!...'\n",
                        "âœ… True: SPAM | Pred: SPAM | 'Claim your free gift card today!...'\n",
                        "âœ… True: OK   | Pred: OK   | 'Hey, can we meet for lunch tomorrow?...'\n",
                        "âœ… True: SPAM | Pred: SPAM | 'Congratulations! You've won a free iPhon...'\n",
                        "âœ… True: SPAM | Pred: SPAM | 'You have been selected for a cash prize!...'\n",
                        "\n",
                        "ðŸ“Š Test Accuracy: 100.00%\n"
                    ]
                }
            ],
            "source": [
                "# Evaluate on test set\n",
                "if success:\n",
                "    classifier.eval()\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    print(\"\\nTest Set Predictions:\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for i, (text_ids, label) in enumerate(test_dataset):\n",
                "            text_ids = text_ids.unsqueeze(0).to(device)\n",
                "            logits = classifier(text_ids)\n",
                "            pred = torch.argmax(logits, dim=1).item()\n",
                "            \n",
                "            text = tokenizer.decode(text_ids[0].tolist()).strip()\n",
                "            status = \"âœ…\" if pred == label else \"âŒ\"\n",
                "            label_str = \"SPAM\" if label == 1 else \"OK\"\n",
                "            pred_str = \"SPAM\" if pred == 1 else \"OK\"\n",
                "            \n",
                "            print(f\"{status} True: {label_str:4} | Pred: {pred_str:4} | '{text[:40]}...'\")\n",
                "            \n",
                "            correct += (pred == label)\n",
                "            total += 1\n",
                "    \n",
                "    print(f\"\\nðŸ“Š Test Accuracy: {correct/total:.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ§ª Try Your Own Messages!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_text(text, classifier, tokenizer, max_length=64):\n",
                "    \"\"\"Classify a single text.\"\"\"\n",
                "    classifier.eval()\n",
                "    tokens = tokenizer.encode(text)\n",
                "    if len(tokens) > max_length:\n",
                "        tokens = tokens[:max_length]\n",
                "    else:\n",
                "        tokens = [tokenizer.encode(\" \")[0]] * (max_length - len(tokens)) + tokens\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        input_ids = torch.tensor(tokens).unsqueeze(0).to(device)\n",
                "        logits = classifier(input_ids)\n",
                "        probs = F.softmax(logits, dim=1)\n",
                "        pred = torch.argmax(logits, dim=1).item()\n",
                "    \n",
                "    return \"SPAM ðŸš¨\" if pred == 1 else \"OK âœ…\", probs[0].tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ” Spam Detection Results:\n",
                        "\n",
                        "SPAM ðŸš¨ (conf: 100.00%): 'You've won $1,000,000! Claim now!'\n",
                        "OK âœ… (conf: 99.94%): 'Can you send me the meeting notes?'\n",
                        "SPAM ðŸš¨ (conf: 99.13%): 'URGENT: Password reset required immediately!'\n",
                        "OK âœ… (conf: 99.93%): 'Thanks for the help yesterday, really appreciated it.'\n"
                    ]
                }
            ],
            "source": [
                "# Test with new messages\n",
                "if success:\n",
                "    test_messages = [\n",
                "        \"You've won $1,000,000! Claim now!\",\n",
                "        \"Can you send me the meeting notes?\",\n",
                "        \"URGENT: Password reset required immediately!\",\n",
                "        \"Thanks for the help yesterday, really appreciated it.\",\n",
                "    ]\n",
                "    \n",
                "    print(\"ðŸ” Spam Detection Results:\\n\")\n",
                "    for msg in test_messages:\n",
                "        result, probs = classify_text(msg, classifier, tokenizer)\n",
                "        print(f\"{result} (conf: {max(probs):.2%}): '{msg}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 4: Workshop Wrap-up (30 min)\n",
                "---\n",
                "\n",
                "## ðŸ“¢ Instructor Script\n",
                "\n",
                "> \"Congratulations everyone! You've just built a Large Language Model from SCRATCH!\"\n",
                "\n",
                "## ðŸ“ What We Accomplished\n",
                "\n",
                "### Day 1\n",
                "- âœ… **Session 1**: Tokenization, embeddings, data loading\n",
                "- âœ… **Session 2**: Self-attention, multi-head attention\n",
                "\n",
                "### Day 2  \n",
                "- âœ… **Session 3**: Complete GPT architecture, text generation\n",
                "- âœ… **Session 4**: Pretraining, loading weights, finetuning\n",
                "\n",
                "### You Now Understand:\n",
                "1. How text becomes numbers (tokenization)\n",
                "2. How attention lets tokens \"see\" each other\n",
                "3. How GPT generates text (next-token prediction)\n",
                "4. How to adapt LLMs for specific tasks (finetuning)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸš€ What's Next?\n",
                "\n",
                "ðŸ“¢ **Say this:**\n",
                "> \"Your LLM journey doesn't end here! Here's what you can explore next:\"\n",
                "\n",
                "### Immediate Next Steps:\n",
                "1. **Run the full notebooks** from [LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)\n",
                "2. **Read the book**: \"Build a Large Language Model From Scratch\"\n",
                "3. **Watch the 17-hour video course** companion\n",
                "\n",
                "### Advanced Topics:\n",
                "1. **Instruction Tuning** (Chapter 7) - Make models follow instructions\n",
                "2. **LoRA** (Appendix E) - Efficient finetuning with fewer parameters\n",
                "3. **DPO/RLHF** - Align models with human preferences\n",
                "4. **Llama, Mistral, Qwen** - Build other architectures\n",
                "\n",
                "### Resources:\n",
                "- ðŸ“– [LLMs from Scratch Book](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
                "- ðŸ’» [GitHub Repository](https://github.com/rasbt/LLMs-from-scratch)\n",
                "- ðŸŽ¥ [Video Course](https://www.manning.com/livevideo/master-and-build-large-language-models)\n",
                "- ðŸ“š [Reasoning From Scratch (sequel)](https://github.com/rasbt/reasoning-from-scratch)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ™‹ Q&A Time\n",
                "\n",
                "ðŸ“¢ **Open floor for questions!**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ðŸŽ‰ Thank You!\n",
                "\n",
                "```\n",
                "   _____ ____  _   _  _____ _____       _______ _____ _ \n",
                "  / ____/ __ \\| \\ | |/ ____|  __ \\     /\\|__   __/ ____| |\n",
                " | |   | |  | |  \\| | |  __| |__) |   /  \\  | | | (___ | |\n",
                " | |   | |  | | . ` | | |_ |  _  /   / /\\ \\ | |  \\___ \\| |\n",
                " | |___| |__| | |\\  | |__| | | \\ \\  / ____ \\| |  ____) |_|\n",
                "  \\_____\\____/|_| \\_|\\_____|_|  \\_\\/_/    \\_\\_| |_____/(_)\n",
                "```\n",
                "\n",
                "You've completed the **Build an LLM From Scratch** workshop!\n",
                "\n",
                "ðŸŒŸ **Keep building, keep learning!** ðŸŒŸ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
