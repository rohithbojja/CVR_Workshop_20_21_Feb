{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM From Scratch \u2014 Interactive Student Workbook (v2)\n",
    "\n",
    "This workbook is now visual + interactive. For each exercise:\n",
    "1. Predict what will happen.\n",
    "2. Run the code.\n",
    "3. Change one parameter and re-run.\n",
    "4. Explain what changed.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 \u2014 Dot Product Visual\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = torch.tensor([2.0, 1.0])\n",
    "b = torch.tensor([1.0, 3.0])\n",
    "c = torch.tensor([-1.0, -3.0])\n",
    "\n",
    "vals = [torch.dot(a,b).item(), torch.dot(a,c).item()]\n",
    "plt.bar(['a\u00b7b','a\u00b7c'], vals)\n",
    "plt.axhline(0, color='black')\n",
    "plt.title('Positive vs Negative Similarity')\n",
    "plt.show()\n",
    "\n",
    "# TODO: change vectors and interpret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \u2014 Softmax Temperature Explorer\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = torch.tensor([2.0, 1.0, 0.1])\n",
    "for T in [2.0, 1.0, 0.5, 0.2]:\n",
    "    p = torch.softmax(scores / T, dim=0)\n",
    "    print(f'T={T}:', p.tolist())\n",
    "\n",
    "# TODO: plot these distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \u2014 Tokenization Timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = 'students can build tiny llms'\n",
    "tokens = text.split()\n",
    "vocab = {w:i for i,w in enumerate(sorted(set(tokens)))}\n",
    "ids = [vocab[t] for t in tokens]\n",
    "print(tokens)\n",
    "print(ids)\n",
    "\n",
    "# TODO: make a scatter timeline plot token->id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \u2014 Attention Heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def attention(Q,K,V):\n",
    "    d = Q.size(-1)\n",
    "    w = torch.softmax((Q @ K.transpose(-2,-1)) / math.sqrt(d), dim=-1)\n",
    "    return w @ V, w\n",
    "\n",
    "X = torch.randn(1,4,8)\n",
    "Wq, Wk, Wv = [torch.randn(8,8) for _ in range(3)]\n",
    "out, w = attention(X@Wq, X@Wk, X@Wv)\n",
    "\n",
    "plt.imshow(w[0].detach().numpy(), cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Attention heatmap')\n",
    "plt.show()\n",
    "\n",
    "# TODO: label axes with custom tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 \u2014 Causal Mask Visual\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "T = 6\n",
    "mask = torch.tril(torch.ones(T,T))\n",
    "plt.imshow(mask.numpy(), cmap='gray_r')\n",
    "plt.title('Causal mask')\n",
    "plt.show()\n",
    "\n",
    "# TODO: explain why upper-right is blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 \u2014 Mini Training Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: build a tiny model and plot loss over 20+ steps\n",
    "# Hint: keep a list called losses, then plt.plot(losses)\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "1. Which visualization made attention easiest to understand?\n",
    "2. How does temperature change randomness in generation?\n",
    "3. Why do we need both embeddings and positional info?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}